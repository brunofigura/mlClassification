{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 style=\"font-size: 30px; color:orange;\">Convolutional Autoencoder (CAE) on the MNIST-Dataset using Tensorflow</h1>\n",
        "<h2 style=\"font-size: 20px;\">Authors: Bruno Figura & Daniel Labuda, ML II Projektarbeit Gruppe 2, SoSe24</h2>\n",
        "-----------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718043640576
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras import layers, models, Input\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the imported dataset into training and test data. Preprocess (reshape and normalize) the dataset. Print out the shapes of the resulting tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718042350587
        }
      },
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
        "\n",
        "train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
        "test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "train_data /= 255\n",
        "test_data /= 255\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "print(\"Training data shape:\\n\", train_data.shape, \"\\n\")\n",
        "print(\"Test data shape:\\n\", test_data.shape, \"\\n\")\n",
        "print(\"Training labels shape:\\n\", train_labels.shape, \"\\n\")\n",
        "print(\"Test labels shape:\\n\", test_labels.shape)\n",
        "\n",
        "random_indices = np.random.choice(train_data.shape[0], 9, replace=False)\n",
        "random_digits = train_data[random_indices]\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(random_digits[i], cmap='gray')\n",
        "    plt.title(f\"Label: {np.argmax(train_labels[random_indices[i]])}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the CNN-Autoencoder (CAE) model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718042355031
        }
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "# 1st convolution layer\n",
        "x = layers.Conv2D(4, (5, 5), padding='same', activation='relu')(input_img)\n",
        "x = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "\n",
        "# 2nd convolution layer\n",
        "x = layers.Conv2D(16, (5, 5), padding='same', activation='relu')(x)\n",
        "encoded = layers.MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = layers.Conv2D(16, (5, 5), padding='same', activation='relu')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = layers.Conv2D(4, (5, 5), padding='same', activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = layers.Conv2D(1, (5, 5), padding='same', activation='sigmoid')(x)\n",
        "\n",
        "# Autoencoder Model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Classifier on top of Encoder\n",
        "x = layers.Flatten()(encoded)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Full model including classifier\n",
        "full_model = Model(input_img, output)\n",
        "\n",
        "autoencoder.summary()\n",
        "full_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compile and train the previously defined architecture on the preprocessed dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718042834170
        }
      },
      "outputs": [],
      "source": [
        "# Compile and train the autoencoder\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(train_data, train_data, batch_size=128, epochs=5, validation_data=(test_data, test_data))\n",
        "\n",
        "# Compile and train the full model\n",
        "full_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "full_model.fit(train_data, train_labels, batch_size=128, epochs=20, validation_data=(test_data, test_labels))\n",
        "\n",
        "#model.save('C:/Users/AL/Desktop/Machine Learning II Thema 2/model_mnist.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot 5 random input-images to be ran through the CAE aswell as the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718043200631
        }
      },
      "outputs": [],
      "source": [
        "# Select 5 random test images\n",
        "num_samples = test_data.shape[0]\n",
        "indices = np.arange(num_samples)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Get the restored images from the autoencoder\n",
        "restored_imgs = autoencoder.predict(test_data)\n",
        "\n",
        "# Create a 2x5 grid for displaying results\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('Autoencoder results: Original and Restored Images')\n",
        "\n",
        "for i in range(5):\n",
        "    random_index = indices[i]\n",
        "\n",
        "    # Original images\n",
        "    axes[0, i].imshow(test_data[random_index].reshape(28, 28), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[0, i].set_title('Original')\n",
        "\n",
        "    # Restored images\n",
        "    axes[1, i].imshow(restored_imgs[random_index].reshape(28, 28), cmap='gray')\n",
        "    axes[1, i].axis('off')\n",
        "    axes[1, i].set_title('Restored')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Get predictions from the classifier\n",
        "predictions = full_model.predict(test_data)\n",
        "\n",
        "# Display classification results\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('Classification results: Original and Predicted Labels')\n",
        "\n",
        "for i in range(5):\n",
        "    random_index = indices[i]\n",
        "\n",
        "    # Original images\n",
        "    axes[0, i].imshow(test_data[random_index].reshape(28, 28), cmap='gray')\n",
        "    axes[0, i].axis('off')\n",
        "    axes[0, i].set_title(f'Original: {np.argmax(test_labels[random_index])}')\n",
        "\n",
        "    # Predicted labels\n",
        "    axes[1, i].imshow(test_data[random_index].reshape(28, 28), cmap='gray')\n",
        "    axes[1, i].axis('off')\n",
        "    axes[1, i].set_title(f'Predicted: {np.argmax(predictions[random_index])}')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1718043672666
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Predict the labels for the test data\n",
        "predicted_labels = np.argmax(full_model.predict(test_data), axis=1)\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='OrRd', xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(true_labels, predicted_labels, digits=3)\n",
        "print('Classification Report:\\n', report)\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "ml2_env"
    },
    "kernelspec": {
      "display_name": "ML2_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "de"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
